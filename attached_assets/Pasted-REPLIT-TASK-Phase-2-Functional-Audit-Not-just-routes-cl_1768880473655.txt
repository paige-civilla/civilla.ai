REPLIT TASK: Phase 2 Functional Audit (Not just routes) + clarify the “401 login failed” line

Context
We already have a navigation/link audit that claims 93/93 working, but it does NOT verify in-app functional buttons or AI pipelines. We also saw “✗ Login failed: 401” in the report even though authenticated routes later show as working. I’m not a developer — I need you to run a true end-to-end functional audit and tell me what’s missing/broken.

GOALS
1) Explain why the audit report shows “✗ Login failed: 401”:
   - Which script produced that line?
   - Was it an expected unauthenticated check mislabeled?
   - Were cookies/session not preserved between steps?
   - Is there a bug in the login helper or env var parsing?
   - Provide the exact fix so future audits authenticate reliably.

2) Produce a “REAL” app audit that tests BUTTONS + DATA + AI start-to-end (case-aware), not just page loads.
   This must validate that clicks → API calls → DB updates → UI updates actually occur.

WHAT TO DO (DO ALL)

A) Create/Update a single command to run the full audit
- Add a single script/command (ex: `npx tsx script/fullFunctionalAudit.ts`) that runs all steps below.
- Output:
  - `audit/functional_audit.json` (machine readable)
  - `AUDIT_FUNCTIONAL_REPORT.md` (human readable)
- Include pass/fail per step with the exact error message + endpoint if it fails.

B) Auth reliability check (fix the 401 issue)
- Verify TEST_EMAIL and TEST_PASSWORD are read correctly (trim whitespace, remove literal “\n”, etc.)
- Confirm login works and session/cookies persist for subsequent calls.
- In the report, include:
  - “Auth: PASS/FAIL”
  - If fail: exact reason and file/line fix.

C) Case-aware end-to-end test flow (MUST implement)
Use the QA test account and do the following in order:

1) Create a new case via API (or UI automation if already available)
- Verify case created and returned caseId.

2) Evidence upload pathway (at least 2 files)
- Upload:
  - One small PDF (2–5 pages)
  - One image (png/jpg screenshot)
- Verify evidence records exist and store IDs.
(If upload scripting is hard, at minimum seed the DB + upload to R2 via existing utilities and then call the same endpoints the UI uses.)

3) Extraction pipeline
- Trigger extraction for each evidence file (OCR/text extraction).
- Verify:
  - evidence_extractions row created
  - status transitions: queued → processing → complete OR failed
  - extractedText populated when complete
- If failed, test the retry endpoint and confirm it can recover.

4) AI analysis pipeline
- Trigger “Run AI analysis” for a completed extraction.
- Verify:
  - evidence_ai_analyses row created
  - status transitions: processing → complete/failed
  - summary/findings populated on success
- If failed, confirm retry works.

5) Claims suggestion pipeline
- Trigger claims suggestion on the same evidence file.
- Verify:
  - 3–10 case_claims created
  - Each claim has >= 1 claim_citations entry
  - Citation pointers include evidenceId + quote/page info

6) Accept/reject + compile from claims
- Accept at least 2 claims.
- Attempt compile:
  - Verify preflight blocks if uncited claims exist (expected)
  - Verify compile succeeds once requirements met
- Verify a document record is created.

7) Exports
- Pattern analysis export endpoint returns a ZIP successfully.
- Trial prep binder export returns a ZIP successfully.
- Document export returns successfully.

8) Lexi core workflow
- Create a Lexi thread (general thread is ok).
- Send a message.
- Verify assistant response saved to lexi_messages.
- Validate sources:
  - sources are absolute URLs (https://…)
  - optionally: HEAD/GET request returns non-404 for each source (limit to 3 checks to avoid rate limits)
- Verify suggested question chips trigger message send (not just opening Lexi).

D) Button-to-endpoint mapping report (required)
Create a table in AUDIT_FUNCTIONAL_REPORT.md:
- Feature/Button name
- UI location (page/component)
- API endpoint(s) called
- DB tables touched
- Result: PASS/FAIL
This should cover at least:
- Create case
- Upload evidence
- Run extraction / retry extraction
- Run AI analysis / retry analysis
- Suggest claims / accept claim / auto-attach sources
- Compile claims to document
- Export document
- Pattern analysis + export
- Trial prep export
- Lexi thread create + send message + sources

E) Identify missing coverage
At the end of the report, list:
- Any app pages/routes NOT covered by functional testing
- Any buttons that exist in the UI but have no working endpoint or navigation
- Any AI features present in UI that are not wired to backend or are failing consistently

OUTPUT REQUIREMENTS
1) Provide the two files:
- AUDIT_FUNCTIONAL_REPORT.md
- audit/functional_audit.json
2) In your reply, summarize:
- What is broken
- What is missing
- Exactly what you fixed (with file names)
- What still needs human testing (if anything)

Important constraints
- Do NOT expose user content or PII in reports.
- Use only the QA account and test case created by the script.
- If Playwright can’t run in Replit, do everything via API + DB assertions.